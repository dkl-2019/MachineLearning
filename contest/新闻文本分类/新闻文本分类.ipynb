{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd0192a88fd96c5f88b0f93f6844c224266c9a88fc5236fe406ecce83d3f919f99d",
   "display_name": "Python 3.9.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "192a88fd96c5f88b0f93f6844c224266c9a88fc5236fe406ecce83d3f919f99d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r'E:/TianChi/新闻文本分类/train_set.csv', sep='\\t')\n",
    "test = pd.read_csv(r'E:/TianChi/新闻文本分类/test_a.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['label', 'text'], dtype='object')\nIndex(['text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train.columns)\n",
    "print(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13}\n"
     ]
    }
   ],
   "source": [
    "print(set(train['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_dict = {'科技': 0, '股票': 1, '体育': 2, '娱乐': 3, '时政': 4, '社会': 5, '教育': 6, '财经': 7, '家居': 8, '游戏': 9, '房产': 10, '时尚': 11, '彩票': 12, '星座': 13}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               label\n",
      "count  200000.000000\n",
      "mean        3.210950\n",
      "std         3.084955\n",
      "min         0.000000\n",
      "25%         1.000000\n",
      "50%         2.000000\n",
      "75%         5.000000\n",
      "max        13.000000\n",
      "----------------------------------------------------------------------------------------------------\n",
      "                                                     text\n",
      "count                                               50000\n",
      "unique                                              49995\n",
      "top     2538 2506 1363 5466 3772 340 922 433 2397 5778...\n",
      "freq                                                    4\n"
     ]
    }
   ],
   "source": [
    "print(train.describe())\n",
    "print(\"-\"*100)\n",
    "print(test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['text']\n",
    "test_text = test['text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "source": [
    "# TFIDF算法\n",
    "### TF-IDF（Term Frequency-InversDocument Frequency）是一种常用于信息处理和数据挖掘的加权技术。该技术采用一种统计方法，根据字词的在文本中出现的次数和在整个语料中出现的文档频率来计算一个字词在整个语料中的重要程度。它的优点是能过滤掉一些常见的却无关紧要的词语，同时保留影响整个文本的重要字词。\n",
    "* TF（Term Frequency）表示某个关键词在整篇文章中出现的频率。\n",
    "* IDF（InversDocument Frequency）表示计算倒文本频率。文本频率是指某个关键词在整个语料所有文章中出现的次数。倒文档频率又称为逆文档频率，它是文档频率的倒数，主要用于降低所有文档中一些常见却对文档影响不大的词语的作用。\n",
    "\n",
    "https://blog.csdn.net/u010417185/article/details/87905899"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "%%time\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)\n",
    "\n",
    "all_word = word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "train_word_features"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 7min 12s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<200000x6977 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 56074040 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TfidfVectorizer(max_features=10000, stop_words='english',\n",
      "                strip_accents='unicode', sublinear_tf=True,\n",
      "                token_pattern='\\\\w{1,}')\n",
      "----------------------------------------------------------------------------------------------------\n",
      "(200000, 6977)\n",
      "  (0, 6957)\t0.06123077163392776\n",
      "  (0, 6942)\t0.028944854620259104\n",
      "  (0, 6888)\t0.031744071761905156\n",
      "  (0, 6885)\t0.020676338854265244\n",
      "  (0, 6883)\t0.05375987933625619\n",
      "  (0, 6875)\t0.05381962538912795\n",
      "  (0, 6860)\t0.02631647954528877\n",
      "  (0, 6823)\t0.052614288744070634\n",
      "  (0, 6800)\t0.0331354885749065\n",
      "  (0, 6799)\t0.04829120486123563\n",
      "  (0, 6778)\t0.06323910946402991\n",
      "  (0, 6770)\t0.04750366673846437\n",
      "  (0, 6733)\t0.027377099389752496\n",
      "  (0, 6716)\t0.042478700068770456\n",
      "  (0, 6709)\t0.07103975901129272\n",
      "  (0, 6683)\t0.05942895089274445\n",
      "  (0, 6669)\t0.026424670052076934\n",
      "  (0, 6642)\t0.025961663258648168\n",
      "  (0, 6627)\t0.05447419515324055\n",
      "  (0, 6619)\t0.02668769442656465\n",
      "  (0, 6615)\t0.08485414478405588\n",
      "  (0, 6600)\t0.0666090009621893\n",
      "  (0, 6595)\t0.07183770165932205\n",
      "  (0, 6594)\t0.02138142869013841\n",
      "  (0, 6576)\t0.031167338327822276\n",
      "  :\t:\n",
      "  (199999, 382)\t0.040504521050004454\n",
      "  (199999, 378)\t0.03345190421737518\n",
      "  (199999, 373)\t0.035933995301440716\n",
      "  (199999, 366)\t0.015216199325329745\n",
      "  (199999, 348)\t0.037427337631748936\n",
      "  (199999, 338)\t0.06529418601808658\n",
      "  (199999, 332)\t0.03303746536220641\n",
      "  (199999, 328)\t0.04820393546024153\n",
      "  (199999, 326)\t0.027724178688520198\n",
      "  (199999, 301)\t0.03217877310231004\n",
      "  (199999, 285)\t0.03422963632576008\n",
      "  (199999, 280)\t0.0175290793663159\n",
      "  (199999, 278)\t0.014253233256567058\n",
      "  (199999, 271)\t0.03987315546206053\n",
      "  (199999, 244)\t0.08265158587188048\n",
      "  (199999, 243)\t0.019348236035357833\n",
      "  (199999, 218)\t0.028213761338990253\n",
      "  (199999, 161)\t0.020633241505613596\n",
      "  (199999, 135)\t0.023422383555193896\n",
      "  (199999, 80)\t0.027194635536969193\n",
      "  (199999, 77)\t0.03124932720190343\n",
      "  (199999, 70)\t0.015634975669612704\n",
      "  (199999, 44)\t0.06500924419375878\n",
      "  (199999, 38)\t0.017166684831494878\n",
      "  (199999, 25)\t0.036953140697283296\n",
      "----------------------------------------------------------------------------------------------------\n",
      "(50000, 6977)\n",
      "  (0, 6915)\t0.04230318363278095\n",
      "  (0, 6896)\t0.06694949340855265\n",
      "  (0, 6875)\t0.060012406973145305\n",
      "  (0, 6860)\t0.06274838829882612\n",
      "  (0, 6844)\t0.047243417087924046\n",
      "  (0, 6822)\t0.04958456461849691\n",
      "  (0, 6778)\t0.02498115147570968\n",
      "  (0, 6721)\t0.0862526387947437\n",
      "  (0, 6716)\t0.025068438050147954\n",
      "  (0, 6710)\t0.06600811394552841\n",
      "  (0, 6669)\t0.02197834232628985\n",
      "  (0, 6642)\t0.10206822971859406\n",
      "  (0, 6622)\t0.07262421184746576\n",
      "  (0, 6570)\t0.019177045772924017\n",
      "  (0, 6549)\t0.027732166641630026\n",
      "  (0, 6460)\t0.06155206377915038\n",
      "  (0, 6427)\t0.055768725006011974\n",
      "  (0, 6356)\t0.029824845687069498\n",
      "  (0, 6347)\t0.06680781347240666\n",
      "  (0, 6201)\t0.03581859499837085\n",
      "  (0, 6133)\t0.09318814697551331\n",
      "  (0, 6089)\t0.08732170094022285\n",
      "  (0, 6055)\t0.055971461372384526\n",
      "  (0, 5985)\t0.027860156477044675\n",
      "  (0, 5963)\t0.040029437322299743\n",
      "  :\t:\n",
      "  (49999, 1514)\t0.029639525891313866\n",
      "  (49999, 1495)\t0.06293688165964989\n",
      "  (49999, 1473)\t0.13208702801091338\n",
      "  (49999, 1453)\t0.21328192064689291\n",
      "  (49999, 1446)\t0.10188884860092758\n",
      "  (49999, 1421)\t0.08022067078597411\n",
      "  (49999, 1321)\t0.22509275926071382\n",
      "  (49999, 1288)\t0.03696233764844749\n",
      "  (49999, 1245)\t0.12271681700086601\n",
      "  (49999, 1232)\t0.05578333659927703\n",
      "  (49999, 1140)\t0.09062894810788069\n",
      "  (49999, 1137)\t0.08379795627964477\n",
      "  (49999, 1102)\t0.12186183495946311\n",
      "  (49999, 1053)\t0.11344375735527204\n",
      "  (49999, 996)\t0.1413467540643503\n",
      "  (49999, 958)\t0.1744773658485744\n",
      "  (49999, 945)\t0.041475107691605236\n",
      "  (49999, 892)\t0.04804136601201676\n",
      "  (49999, 874)\t0.085557983503245\n",
      "  (49999, 720)\t0.040919909820317214\n",
      "  (49999, 715)\t0.05344879178120399\n",
      "  (49999, 473)\t0.045000404250762294\n",
      "  (49999, 469)\t0.03624683897333995\n",
      "  (49999, 329)\t0.1548732355969802\n",
      "  (49999, 76)\t0.13427567871066123\n"
     ]
    }
   ],
   "source": [
    "print(all_word)\n",
    "print(\"-\"*100)\n",
    "print(train_word_features.shape)\n",
    "print(train_word_features)\n",
    "print(\"-\"*100)\n",
    "print(test_word_features.shape)\n",
    "print(test_word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_word_features\n",
    "y_train = train['label']\n",
    "\n",
    "# 可以改变输入维度\n",
    "x_train_, x_valid_, y_train_, y_valid_ = train_test_split(X_train, y_train, test_size=0.2)\n",
    "X_test = test_word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 6975)\t0.16319325252062827\n  (0, 6933)\t0.05793608590457798\n  (0, 6885)\t0.048890820586192284\n  (0, 6875)\t0.054601169028187034\n  (0, 6860)\t0.036752489773671605\n  (0, 6848)\t0.04083858817402098\n  (0, 6778)\t0.06464550352185065\n  (0, 6733)\t0.08023772712415099\n  (0, 6716)\t0.024860289219139388\n  (0, 6684)\t0.04393067635592298\n  (0, 6669)\t0.021795851249120552\n  (0, 6659)\t0.04161845269305206\n  (0, 6619)\t0.0372709128820683\n  (0, 6570)\t0.053093163674429636\n  (0, 6549)\t0.04656476491600003\n  (0, 6537)\t0.050079531400582744\n  (0, 6474)\t0.03839892665391913\n  (0, 6460)\t0.0610409832684235\n  (0, 6375)\t0.03785881743865962\n  (0, 6356)\t0.029577203342845436\n  (0, 6335)\t0.2863652752687756\n  (0, 6284)\t0.054906754080296154\n  (0, 6221)\t0.03267921928494529\n  (0, 6207)\t0.030451585881911696\n  (0, 6201)\t0.03552118521710065\n  :\t:\n  (159999, 398)\t0.03216214019583148\n  (159999, 378)\t0.043688186781067125\n  (159999, 366)\t0.0487429272926725\n  (159999, 356)\t0.042581860973073316\n  (159999, 348)\t0.032978386809525584\n  (159999, 329)\t0.09308402772948049\n  (159999, 326)\t0.04149734535389102\n  (159999, 293)\t0.02704414713648037\n  (159999, 285)\t0.020255354540221277\n  (159999, 280)\t0.04190978167554207\n  (159999, 278)\t0.029969388397781075\n  (159999, 265)\t0.03768054776130463\n  (159999, 243)\t0.046259152069725924\n  (159999, 234)\t0.03184380614952836\n  (159999, 229)\t0.06356299049915616\n  (159999, 218)\t0.016695466273603358\n  (159999, 217)\t0.04935845834950028\n  (159999, 208)\t0.02903077936921869\n  (159999, 187)\t0.045455056734188586\n  (159999, 168)\t0.03933139423261134\n  (159999, 153)\t0.044730967450809324\n  (159999, 135)\t0.02346731293028229\n  (159999, 80)\t0.042878276796691324\n  (159999, 70)\t0.03738122254583622\n  (159999, 38)\t0.036095322089837185\n----------------------------------------------------------------------------------------------------\n  (0, 6896)\t0.10724944241864376\n  (0, 6875)\t0.06582966718955066\n  (0, 6860)\t0.10051950082206212\n  (0, 6844)\t0.07568138133191617\n  (0, 6721)\t0.04066400492029936\n  (0, 6347)\t0.18620862398727797\n  (0, 6207)\t0.0832862815809206\n  (0, 6142)\t0.1357233043962935\n  (0, 6133)\t0.08816855274513637\n  (0, 5962)\t0.049877703364151815\n  (0, 5796)\t0.061807562950905774\n  (0, 5790)\t0.05553436368720638\n  (0, 5629)\t0.02837905848416576\n  (0, 5396)\t0.18494275607308477\n  (0, 5388)\t0.11744569065885285\n  (0, 5245)\t0.04578204010043676\n  (0, 5232)\t0.08215568430359792\n  (0, 5205)\t0.08944930922514675\n  (0, 4917)\t0.03906628929933429\n  (0, 4823)\t0.08175854256410606\n  (0, 4822)\t0.10501546675245053\n  (0, 4732)\t0.113602307870506\n  (0, 4718)\t0.04449222585896392\n  (0, 4621)\t0.03825802005950005\n  (0, 4470)\t0.06632905195745065\n  :\t:\n  (39999, 580)\t0.0600744465744681\n  (39999, 577)\t0.038893819324474575\n  (39999, 575)\t0.02698797801483515\n  (39999, 469)\t0.04098216625878015\n  (39999, 424)\t0.055221610147330104\n  (39999, 406)\t0.019218581032942154\n  (39999, 398)\t0.016787526484208785\n  (39999, 391)\t0.07196073379042585\n  (39999, 348)\t0.05464381080693176\n  (39999, 343)\t0.01876164562009842\n  (39999, 326)\t0.05376236198136965\n  (39999, 301)\t0.04015758087313551\n  (39999, 293)\t0.03368519573112059\n  (39999, 278)\t0.01778735831177997\n  (39999, 265)\t0.02236406681105605\n  (39999, 249)\t0.0354833649580571\n  (39999, 229)\t0.030340528312567876\n  (39999, 221)\t0.03015505143214583\n  (39999, 218)\t0.020795259189003334\n  (39999, 155)\t0.05914575812419471\n  (39999, 143)\t0.02040278837539745\n  (39999, 100)\t0.07511167752651926\n  (39999, 80)\t0.03858985149883999\n  (39999, 70)\t0.06629873777256375\n  (39999, 38)\t0.05980844250157855\n----------------------------------------------------------------------------------------------------\n142973    4\n34916     7\n141142    0\n84670     2\n153064    0\n         ..\n163279    0\n185575    2\n98649     0\n19894     1\n135154    1\nName: label, Length: 160000, dtype: int64\n----------------------------------------------------------------------------------------------------\n25904     1\n147903    0\n102555    0\n60647     0\n192692    0\n         ..\n199038    7\n125963    1\n161959    0\n147922    2\n83661     2\nName: label, Length: 40000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(x_train_)\n",
    "print(\"-\"*100)\n",
    "print(x_valid_)\n",
    "print(\"-\"*100)\n",
    "print(y_train_)\n",
    "print(\"-\"*100)\n",
    "print(y_valid_)"
   ]
  },
  {
   "source": [
    "# 逻辑回归\n",
    "### f1_score\n",
    "https://blog.csdn.net/fengdu78/article/details/107739416\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnicodeEncodeError",
     "evalue": "'ascii' codec can't encode characters in position 18-20: ordinal not in range(128)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1404\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1407\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_effective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_initialize_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m         \u001b[1;34m\"\"\"Build a process or thread pool and return the number of workers\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m             n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n\u001b[0m\u001b[0;32m    734\u001b[0m                                              **self._backend_args)\n\u001b[0;32m    735\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msupports_timeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mconfigure\u001b[1;34m(self, n_jobs, parallel, prefer, require, idle_worker_timeout, **memmappingexecutor_args)\u001b[0m\n\u001b[0;32m    492\u001b[0m                 SequentialBackend(nesting_level=self.nesting_level))\n\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m         self._workers = get_memmapping_executor(\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midle_worker_timeout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m             \u001b[0menv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_worker_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\executor.py\u001b[0m in \u001b[0;36mget_memmapping_executor\u001b[1;34m(n_jobs, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_memmapping_executor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mMemmappingExecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_memmapping_executor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\executor.py\u001b[0m in \u001b[0;36mget_memmapping_executor\u001b[1;34m(cls, n_jobs, timeout, initializer, initargs, env, temp_folder, context_id, **backend_args)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0m_executor_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecutor_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTemporaryResourcesManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# reducers access the temporary folder in which to store temporary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, temp_folder_root, context_id)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[1;31m# exposes exposes too many low-level details.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mcontext_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muuid4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_current_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_current_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36mset_current_context\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_current_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_context_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 535\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_new_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_new_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36mregister_new_context\u001b[1;34m(self, context_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m                 \u001b[0mnew_folder_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_folder_root\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             )\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister_folder_finalizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_folder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_temp_folders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcontext_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_folder_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\_memmapping_reducer.py\u001b[0m in \u001b[0;36mregister_folder_finalizer\u001b[1;34m(self, pool_subfolder, context_id)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# semaphores and pipes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[0mpool_module_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhichmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelete_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'delete_folder'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mresource_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_subfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"folder\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_cleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py\u001b[0m in \u001b[0;36mregister\u001b[1;34m(self, name, rtype)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;34m'''Register a named resource, and increment its refcount.'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'REGISTER'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0munregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\joblib\\externals\\loky\\backend\\resource_tracker.py\u001b[0m in \u001b[0;36m_send\u001b[1;34m(self, cmd, name, rtype)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_send\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{0}:{1}:{2}\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ascii'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[1;31m# posix guarantees that writes to a pipe of less than PIPE_BUF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'ascii' codec can't encode characters in position 18-20: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LogisticRegression(C=4, n_jobs=16)\n",
    "clf.fit(x_train_, y_train_)\n",
    "\n",
    "y_pred = clf.predict(x_valid_)\n",
    "train_scores = clf.score(x_train_, y_train_)\n",
    "print(train_scores, f1_score(y_pred, y_valid_, average='macro'))"
   ]
  },
  {
   "source": [
    "# XGB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_, x_valid_, y_train_, y_valid_ = train_test_split(X_train[:, :300], y_train, test_size=0.2, shuffle=True,random_state=42)\n",
    "X_test = test_word_features[:,:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(200000, 300)\n",
      "  (0, 293)\t0.06788293187676152\n",
      "  (0, 280)\t0.04408376561395052\n",
      "  (0, 273)\t0.047504015874521174\n",
      "  (0, 243)\t0.02873864199901826\n",
      "  (0, 221)\t0.09365562055916186\n",
      "  (0, 217)\t0.03486759271969195\n",
      "  (0, 214)\t0.05243303349303011\n",
      "  (0, 143)\t0.041116017387529444\n",
      "  (0, 100)\t0.08939933038358235\n",
      "  (0, 33)\t0.02601467000614618\n",
      "  (1, 289)\t0.14211398894422123\n",
      "  (1, 278)\t0.024839717563377835\n",
      "  (1, 159)\t0.0637338662894813\n",
      "  (1, 155)\t0.04878250423618895\n",
      "  (1, 61)\t0.12146474235410022\n",
      "  (1, 58)\t0.14213998097105388\n",
      "  (2, 285)\t0.02772347165843572\n",
      "  (2, 280)\t0.024038045219873218\n",
      "  (2, 278)\t0.019545799205470105\n",
      "  (2, 273)\t0.025903043122885\n",
      "  (2, 268)\t0.036387523626886915\n",
      "  (2, 263)\t0.0707844024387805\n",
      "  (2, 255)\t0.07159214985429842\n",
      "  (2, 249)\t0.0389912158088862\n",
      "  (2, 247)\t0.039072113392983714\n",
      "  :\t:\n",
      "  (199997, 143)\t0.06801290716004449\n",
      "  (199997, 135)\t0.027960170438285813\n",
      "  (199997, 70)\t0.01866405199499365\n",
      "  (199997, 65)\t0.025169598371429677\n",
      "  (199997, 58)\t0.04639375303759279\n",
      "  (199997, 46)\t0.04545905259123971\n",
      "  (199997, 38)\t0.02049251019299001\n",
      "  (199997, 20)\t0.024570558359567826\n",
      "  (199998, 100)\t0.18803817519461513\n",
      "  (199998, 70)\t0.0933686496375287\n",
      "  (199999, 285)\t0.03422963632576008\n",
      "  (199999, 280)\t0.0175290793663159\n",
      "  (199999, 278)\t0.014253233256567058\n",
      "  (199999, 271)\t0.03987315546206053\n",
      "  (199999, 244)\t0.08265158587188048\n",
      "  (199999, 243)\t0.019348236035357833\n",
      "  (199999, 218)\t0.028213761338990253\n",
      "  (199999, 161)\t0.020633241505613596\n",
      "  (199999, 135)\t0.023422383555193896\n",
      "  (199999, 80)\t0.027194635536969193\n",
      "  (199999, 77)\t0.03124932720190343\n",
      "  (199999, 70)\t0.015634975669612704\n",
      "  (199999, 44)\t0.06500924419375878\n",
      "  (199999, 38)\t0.017166684831494878\n",
      "  (199999, 25)\t0.036953140697283296\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  (0, 170)\t0.07601870530101057\n",
      "  (0, 119)\t0.07080635126580828\n",
      "  (0, 105)\t0.0808290289527261\n",
      "  (0, 47)\t0.1547055049637102\n",
      "  (1, 265)\t0.0267891110156934\n",
      "  (1, 229)\t0.06153544867329193\n",
      "  (1, 218)\t0.024909892807998747\n",
      "  (1, 161)\t0.07360326140509864\n",
      "  (1, 143)\t0.024439766140745642\n",
      "  (1, 105)\t0.04278280866428276\n",
      "  (1, 100)\t0.10643553194117872\n",
      "  (1, 80)\t0.032798299327752446\n",
      "  (1, 70)\t0.0652500411289643\n",
      "  (1, 38)\t0.04344969455395047\n",
      "  (1, 33)\t0.026181772081391403\n",
      "  (1, 20)\t0.07342363764204911\n",
      "  (1, 14)\t0.03709915675672885\n",
      "  (1, 10)\t0.04498833461417711\n",
      "  (2, 285)\t0.05053489042331904\n",
      "  (2, 280)\t0.04791437366656999\n",
      "  (2, 278)\t0.014930458084923574\n",
      "  (2, 271)\t0.05176996197162391\n",
      "  (2, 244)\t0.04125520215154084\n",
      "  (2, 243)\t0.04253371615941427\n",
      "  (2, 229)\t0.060772742147987266\n",
      "  :\t:\n",
      "  (159997, 278)\t0.0451858436974319\n",
      "  (159997, 218)\t0.025172309807651682\n",
      "  (159997, 155)\t0.04228512527788413\n",
      "  (159997, 152)\t0.053054313770504576\n",
      "  (159997, 148)\t0.04680491615617255\n",
      "  (159997, 143)\t0.06444588965245503\n",
      "  (159997, 135)\t0.05990769249567244\n",
      "  (159997, 80)\t0.05108045895712917\n",
      "  (159997, 77)\t0.04720602836858625\n",
      "  (159997, 76)\t0.06238229706538442\n",
      "  (159997, 70)\t0.02361859185745723\n",
      "  (159997, 33)\t0.0555242190616652\n",
      "  (159997, 14)\t0.037489983384558764\n",
      "  (159998, 285)\t0.02937843101426962\n",
      "  (159998, 273)\t0.027449331556344724\n",
      "  (159998, 218)\t0.024215157685645874\n",
      "  (159998, 135)\t0.03403706573704062\n",
      "  (159998, 70)\t0.04768155895124198\n",
      "  (159998, 69)\t0.1892252597505344\n",
      "  (159998, 38)\t0.024946375705946475\n",
      "  (159999, 278)\t0.03699791609911481\n",
      "  (159999, 221)\t0.06272286436778811\n",
      "  (159999, 146)\t0.19393527579710618\n",
      "  (159999, 70)\t0.04058458229254832\n",
      "  (159999, 46)\t0.058382247999496234\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  (1, 243)\t0.04667857366693276\n",
      "  (1, 229)\t0.05865449201025299\n",
      "  (1, 221)\t0.12234054875692177\n",
      "  (1, 153)\t0.10770905497274252\n",
      "  (1, 80)\t0.031262753865391235\n",
      "  (1, 33)\t0.04225417785378736\n",
      "  (2, 278)\t0.03536309626256702\n",
      "  (2, 100)\t0.1415157548784505\n",
      "  (3, 285)\t0.04033238971010725\n",
      "  (3, 278)\t0.028435428306492472\n",
      "  (3, 273)\t0.03768401168444644\n",
      "  (3, 269)\t0.08942979955181912\n",
      "  (3, 268)\t0.052936941000272485\n",
      "  (3, 218)\t0.03324395289165679\n",
      "  (3, 119)\t0.08468561728123096\n",
      "  (3, 38)\t0.07187287659410439\n",
      "  (4, 285)\t0.03442918189790023\n",
      "  (4, 280)\t0.04207339334450254\n",
      "  (4, 273)\t0.053041178410582056\n",
      "  (4, 265)\t0.030519108963742582\n",
      "  (4, 229)\t0.08521982635831504\n",
      "  (4, 195)\t0.0795090753442339\n",
      "  (4, 155)\t0.047670527750516584\n",
      "  (4, 148)\t0.05276595587267636\n",
      "  (4, 80)\t0.04304566937542551\n",
      "  :\t:\n",
      "  (39997, 70)\t0.06291443871477811\n",
      "  (39997, 65)\t0.10474086544200124\n",
      "  (39997, 20)\t0.12373391840774989\n",
      "  (39998, 293)\t0.0325111039212305\n",
      "  (39998, 278)\t0.029066906024134788\n",
      "  (39998, 261)\t0.06296363241711954\n",
      "  (39998, 258)\t0.03737205785737776\n",
      "  (39998, 249)\t0.03424659826336021\n",
      "  (39998, 243)\t0.0686517442188583\n",
      "  (39998, 221)\t0.02910400220577641\n",
      "  (39998, 217)\t0.047872103737936815\n",
      "  (39998, 152)\t0.042301387456892776\n",
      "  (39998, 143)\t0.08666685000158851\n",
      "  (39998, 123)\t0.03495382650219726\n",
      "  (39998, 80)\t0.026426305126691297\n",
      "  (39998, 77)\t0.037638419091772325\n",
      "  (39998, 65)\t0.04299846715049832\n",
      "  (39998, 46)\t0.027089915163825664\n",
      "  (39998, 38)\t0.05395405670894008\n",
      "  (39998, 33)\t0.021095224812308872\n",
      "  (39998, 25)\t0.04450840772779447\n",
      "  (39998, 20)\t0.059159026279103404\n",
      "  (39999, 278)\t0.047005363724341984\n",
      "  (39999, 70)\t0.05156217574933539\n",
      "  (39999, 65)\t0.06953469992025085\n",
      "----------------------------------------------------------------------------------------------------\n",
      "153248     3\n",
      "67802      2\n",
      "148889     1\n",
      "103093     4\n",
      "104681     3\n",
      "          ..\n",
      "119879     3\n",
      "103694     2\n",
      "131932     1\n",
      "146867    12\n",
      "121958     3\n",
      "Name: label, Length: 160000, dtype: int64\n",
      "----------------------------------------------------------------------------------------------------\n",
      "119737     4\n",
      "72272      2\n",
      "158154     4\n",
      "65426     10\n",
      "30074      1\n",
      "          ..\n",
      "4174      10\n",
      "91537      0\n",
      "156449     0\n",
      "184376     1\n",
      "6584       3\n",
      "Name: label, Length: 40000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:, :300].shape)\n",
    "print(X_train[:, :300])\n",
    "print(\"-\"*100)\n",
    "print(x_train_)\n",
    "print(\"-\"*100)\n",
    "print(x_valid_)\n",
    "print(\"-\"*100)\n",
    "print(y_train_)\n",
    "print(\"-\"*100)\n",
    "print(y_valid_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\董坤凌\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py:430: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n",
      "C:\\Users\\董坤凌\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "Wall time: 7min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param = {'learning_rate': 0.05,         #  (xgb’s “eta”)\n",
    "              'objective': 'multi:softmax', \n",
    "              'n_jobs': 16,\n",
    "              'n_estimators': 300,           # 树的个数\n",
    "              'max_depth': 10,               \n",
    "              'gamma': 0.5,                  # 惩罚项中叶子结点个数前的参数，Increasing this value will make model more conservative.\n",
    "              'reg_alpha': 0,               # L1 regularization term on weights.Increasing this value will make model more conservative.\n",
    "              'reg_lambda': 2,              # L2 regularization term on weights.Increasing this value will make model more conservative.\n",
    "              'min_child_weight' : 1,      # 叶子节点最小权重\n",
    "              'subsample':0.8,             # 随机选择80%样本建立决策树\n",
    "              'random_state':1           # 随机数\n",
    "             }\n",
    "\n",
    "model = XGBClassifier(param)\n",
    "model.fit(x_train_, y_train_, eval_set=[(x_train_, y_train_)],\n",
    "                       eval_metric=['mlogloss'],\n",
    "                       early_stopping_rounds=10,  # 连续N次分值不再优化则提前停止\n",
    "                       verbose=False\n",
    "                      )\n",
    "train_result, train_proba = model.predict(x_train_), model.predict_proba(x_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train_result.shape : \n(160000,)\ntrain_result : \n[ 3  2  1 ...  1 12  0]\n----------------------------------------------------------------------------------------------------\ny_train_.shape : \n(160000,)\n----------------------------------------------------------------------------------------------------\ntrain_proba.shape : \n(160000, 14)\ntrain_proba : \n[[1.66867487e-02 4.18164488e-03 9.51950811e-03 ... 1.46730687e-03\n  6.47020701e-04 1.20726263e-03]\n [3.19576100e-03 1.49288017e-03 9.78947937e-01 ... 2.00482100e-05\n  7.25847110e-03 7.81182553e-06]\n [1.29233047e-01 3.02949131e-01 7.22355098e-02 ... 9.67446773e-04\n  3.55880358e-04 7.05102633e-04]\n ...\n [2.44105067e-02 8.62139761e-01 7.76413223e-03 ... 6.08526578e-04\n  5.30647638e-04 6.11736978e-05]\n [3.26759554e-02 1.12922043e-01 3.82110253e-02 ... 5.19639160e-03\n  6.35578394e-01 2.09927885e-03]\n [6.71953142e-01 1.04622275e-01 3.77040468e-02 ... 8.85093305e-03\n  1.97779294e-03 3.53217649e-04]]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_result.shape : \")\n",
    "print(train_result.shape)\n",
    "print(\"train_result : \")\n",
    "print(train_result)\n",
    "print(\"-\"*100)\n",
    "print(\"y_train_.shape : \")\n",
    "print(y_train_.shape)\n",
    "print(\"-\"*100)\n",
    "print(\"train_proba.shape : \")\n",
    "print(train_proba.shape)\n",
    "print(\"train_proba : \")\n",
    "print(train_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.72426875\n0.6975893853374654\n"
     ]
    }
   ],
   "source": [
    "train_acc = accuracy_score(y_train_, train_result)\n",
    "train_auc = f1_score(y_train_, train_result, average='macro')\n",
    "print(train_acc)\n",
    "print(train_auc)"
   ]
  },
  {
   "source": [
    " 下面代码是封装之后的，，上述相同部分用来测试"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(param):\n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(x_train_, y_train_, eval_set=[(x_train_, y_train_)],\n",
    "                       eval_metric=['mlogloss'],\n",
    "                       early_stopping_rounds=10,  # 连续N次分值不再优化则提前停止\n",
    "                       verbose=False\n",
    "                      )\n",
    "    train_result, train_proba = model.predict(x_train_), model.predict_proba(x_train_)\n",
    "    train_acc = accuracy_score(y_train_, train_result)\n",
    "    train_auc = f1_score(y_train_, train_result, average='macro')\n",
    "\n",
    "    print(\"Train acc: %.2f%% Train auc: %.2f\" % (train_acc*100.0, train_auc))\n",
    "    \n",
    "    return train_result, train_proba, train_acc, train_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X_test, y_test):\n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(x_train_, y_train_, eval_set=[(x_train_, y_train_)],\n",
    "                       eval_metric=['mlogloss'],\n",
    "                       early_stopping_rounds=10,  # 连续N次分值不再优化则提前停止\n",
    "                       verbose=False\n",
    "                      )\n",
    "    result, proba = model.predict(X_test), model.predict_proba(X_test)\n",
    "    acc = accuracy_score(y_test, result)\n",
    "    f1 = f1_score(y_test, result, average='macro')\n",
    "    \n",
    "    print(\"acc: %.2f%% F1_score: %.2f%%\" % (acc*100.0, f1))\n",
    "\n",
    "    return result, proba, acc, f1"
   ]
  },
  {
   "source": [
    "## 网格搜索"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(param_grid):\n",
    "    xgb_model = XGBClassifier(nthread=20)\n",
    "    clf = GridSearchCV(xgb_model, param_grid, scoring='f1_macro', cv=2, verbose=1)\n",
    "    clf.fit(x_train_, y_train_)\n",
    "    print(\"Best score: %f using parms: %s\" % (clf.best_score_, clf.best_params_))\n",
    "    return clf.best_params_, clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\董坤凌\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-b415d1483176>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(param)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     model.fit(x_train_, y_train_, eval_set=[(x_train_, y_train_)],\n\u001b[0m\u001b[0;32m      4\u001b[0m                        \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mlogloss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                        \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# 连续N次分值不再优化则提前停止\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         )\n\u001b[0;32m   1175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m         self._Booster = train(\n\u001b[0m\u001b[0;32m   1177\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \"\"\"\n\u001b[1;32m--> 189\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    190\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1500\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_result, train_proba, train_acc, train_auc = train(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "result, proba, acc, f1 = test(x_valid_, y_valid_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train运行结果：\" + \"-\"*100)\n",
    "print(\"train_result : \")\n",
    "print(train_result)\n",
    "\n",
    "print(\"train_proba : \")\n",
    "print(train_proba)\n",
    "\n",
    "print(\"train_acc : \" + train_acc)\n",
    "print(\"train_auc : \" + train_auc)\n",
    "\n",
    "print(\"-\"*150)\n",
    "\n",
    "print(\"test运行结果：\" + \"-\"*100)\n",
    "print(\"result : \")\n",
    "print(result)\n",
    "\n",
    "print(\"proba : \")\n",
    "print(proba)\n",
    "\n",
    "print(\"acc : \" + acc)\n",
    "print(\"f1 : \" + f1)"
   ]
  },
  {
   "source": [
    "## 结果文件保存"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(r'./test_a_sample_submit.csv'))\n",
    "submission['label'] = preds"
   ]
  }
 ]
}