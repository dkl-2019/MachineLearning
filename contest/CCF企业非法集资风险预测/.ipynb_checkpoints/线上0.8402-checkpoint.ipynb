{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\dask\\dataframe\\utils.py:14: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cab\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,precision_recall_fscore_support,roc_curve,auc,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import gc\n",
    "#from featexp import get_univariate_plots#用于特征筛选，需要先安装featexp\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif']=['Simhei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../train/entprise_info.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-39e954685b2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mentprise_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../train/entprise_info.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'python'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbase_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../train/base_info.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'python'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mentprise_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../entprise_evaluate.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mreccap_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../reccap_predict.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reccap'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mempnum_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../empnum_predict.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'empnum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1187\u001b[0m                     \u001b[1;34m'are \"c\", \"python\", or \"python-fwf\")'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m                 )\n\u001b[1;32m-> 1189\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, **kwds)\u001b[0m\n\u001b[0;32m   2385\u001b[0m             \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2386\u001b[0m             \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2387\u001b[1;33m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2388\u001b[0m         )\n\u001b[0;32m   2389\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors)\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../train/entprise_info.csv'"
     ]
    }
   ],
   "source": [
    "entprise_train = pd.read_csv('/train/entprise_info.csv',engine='python')\n",
    "base_info = pd.read_csv('/train/base_info.csv',engine='python',encoding='utf-8')\n",
    "entprise_test = pd.read_csv('../entprise_evaluate.csv')\n",
    "reccap_predict = pd.read_csv('../reccap_predict.csv')['reccap']\n",
    "empnum_predict = pd.read_csv('../empnum_predict.csv')['empnum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entprise = pd.concat([entprise_train,entprise_test])\n",
    "data = pd.merge(entprise,base_info,on='id')\n",
    "data.drop(['ptbusscope','midpreindcode','score'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['enttypeitem'] = data['enttypegb']//10*10\n",
    "data['enttypeminu'] = data['enttypegb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['regcap'] = data['regcap'].fillna(data['regcap'].mean())\n",
    "data['reccap'] = reccap_predict\n",
    "data['empnum'] = empnum_predict\n",
    "data['reccap'] = data['reccap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['opform'].fillna(10,inplace=True)\n",
    "data['opform'] = data['opform'].astype(str)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder1 = LabelEncoder()\n",
    "labelencoder2 = LabelEncoder()\n",
    "labelencoder3 = LabelEncoder()\n",
    "labelencoder4 = LabelEncoder()\n",
    "data['opform'] = labelencoder1.fit_transform(data['opform'])\n",
    "data['oploc'] = labelencoder2.fit_transform(data['oploc'])\n",
    "data['industryphy'] = labelencoder3.fit_transform(data['industryphy'])\n",
    "data['oplocdistrict'] = labelencoder4.fit_transform(data['oplocdistrict'])\n",
    "def opto_process(x):\n",
    "    if len(x)>3:\n",
    "        return x[:4]\n",
    "    else:\n",
    "        return x\n",
    "data['opfrom'] = data['opfrom'].map(lambda x:x[:4])\n",
    "data['opto'].fillna('nan',inplace=True)\n",
    "data['opto'] = data['opto'].map(opto_process)\n",
    "data['opfrom'] = data['opfrom'].astype(int)\n",
    "data['opto'] = data['opto'].astype(float)\n",
    "data['industryco'] = data['industryco'].fillna(data['industryco'].mean())\n",
    "data.loc[data['opto'].isnull(),\"opto\"] = data[data['opto'].isnull()]['opfrom']+50.0\n",
    "data['enttpe_year'] = data['opfrom'] - data['opto']\n",
    "data['opscope'] = data['opscope'].apply(lambda x:x.replace(\"、\",\"/\").replace(\"；\",\"/\").replace(\"，\",\"/\").replace(\"。\",\"/\"))\n",
    "data['opscope'] = data['opscope'].apply(lambda x:x.replace(\"（\",\"/\").replace(\"）\",\"/\").replace(\"，\",\"/\").replace(\"。\",\"/\"))\n",
    "data['opscope'] = data['opscope'].apply(lambda x:\"\".join(x.split(\"/\")))\n",
    "import jieba\n",
    "data['opscope_1'] = data['opscope'].apply(lambda x:jieba.lcut(x,cut_all=True))\n",
    "from collections import Counter\n",
    "def jieba_func(x):\n",
    "    str1 = list(Counter(x).keys())[0]\n",
    "    str2 = list(Counter(x).keys())[1]\n",
    "    count = str1+str2\n",
    "    return count\n",
    "data['count_opscope'] = data['opscope'].apply(lambda x:jieba_func(x))\n",
    "le6 = LabelEncoder()\n",
    "data['opscope_length'] = data['opscope_1'].apply(lambda x:len(x))\n",
    "# data['opscope'] = data['opscope'].apply(lambda x:x.split('/')[-2:])\n",
    "data['opscope_label'] = le6.fit_transform(data['count_opscope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket(name,bucket_len):\n",
    "    gap_list=[data[name].quantile(i/bucket_len) for i in range(bucket_len+1)]\n",
    "    len_data=len(data[name])\n",
    "    new_col=[]\n",
    "    for i in data[name].values:\n",
    "        for j in range(len(gap_list)):\n",
    "            if gap_list[j]>=i:\n",
    "                encode=j\n",
    "                break\n",
    "        new_col.append(encode)\n",
    "    return new_col\n",
    "#注册资本_实缴资本\n",
    "data['regcap_reccap']=data['regcap']-data['reccap']\n",
    "#注册资本分桶\n",
    "data['regcap']=data['regcap'].fillna(data['regcap'].median())\n",
    "data['bucket_regcap']=bucket('regcap',5)\n",
    "#实缴资本分桶\n",
    "data['reccap']=data['reccap'].fillna(data['reccap'].median())\n",
    "data['bucket_reccap']=bucket('reccap',5)\n",
    "#注册资本_实缴资本分桶\n",
    "data['regcap_reccap']=data['regcap_reccap'].fillna(data['regcap_reccap'].median())\n",
    "data['bucket_regcap_reccap']=bucket('regcap_reccap',5)\n",
    "print('分桶完毕.................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['dom'] = data['dom'].apply(lambda x:x[:16])\n",
    "le7 = LabelEncoder()\n",
    "data['dom'] = le7.fit_transform(data['dom'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['dom_1'] = data['dom'].apply(lambda x:x[:16])\n",
    "# data['dom_2'] = data['dom'].apply(lambda x:x[16:32])\n",
    "# data['dom_3'] = data['dom'].apply(lambda x:x[32:48])\n",
    "# data['dom_4'] = data['dom'].apply(lambda x:x[48:64])\n",
    "# data['dom_5'] = data['dom'].apply(lambda x:x[64:80])\n",
    "# data['dom_6'] = data['dom'].apply(lambda x:x[80:])\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# features_name = [i for i in data.columns if i in [\"dom\",\"dom_1\",\"dom_2\",\"dom_3\",\"dom_4\",\"dom_5\",\"dom_6\"]]\n",
    "# for i in features_name:\n",
    "#     le = LabelEncoder()\n",
    "#     data[i+'_label'] = le.fit_transform(data[i])\n",
    "# #data['finall_label'] = data['dom_1_label']+data['dom_2_label']+data['dom_3_label']+data['dom_4_label']+data['dom_5_label']+data['dom_6_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def cross_two(name_1,name_2):\n",
    "    new_col=[]\n",
    "    encode=0\n",
    "    dic={}\n",
    "    val_1=data[name_1]\n",
    "    val_2=data[name_2]\n",
    "    for i in tqdm(range(len(val_1))):\n",
    "        tmp=str(val_1[i])+'_'+str(val_2[i])\n",
    "        if tmp in dic:\n",
    "            new_col.append(dic[tmp])\n",
    "        else:\n",
    "            dic[tmp]=encode\n",
    "            new_col.append(encode)\n",
    "            encode+=1\n",
    "    return new_col\n",
    "#作企业类型-小类的交叉特征\n",
    "data['enttypegb']=data['enttypegb'].fillna(\"无\")\n",
    "data['enttypeitem']=data['enttypeitem'].fillna(\"无\")\n",
    "new_col=cross_two('enttypegb','enttypeitem')#作企业类型-小类的交叉特征\n",
    "data['enttypegb_enttypeitem']=new_col\n",
    "#\n",
    "#行业类别-细类的交叉特征\n",
    "data['industryphy']=data['industryphy'].fillna(\"无\")\n",
    "data['industryco']=data['industryco'].fillna(\"无\")\n",
    "new_col=cross_two('industryphy','industryco')#作企业类型-小类的交叉特征\n",
    "data['industryphy_industryco']=new_col\n",
    "#企业类型-行业类别的交叉特征\n",
    "new_col=cross_two('enttypegb','industryphy')#作企业类型-小类的交叉特征\n",
    "data['enttypegb_industryphy']=new_col\n",
    "#行业类别-企业类型小类的交叉特征\n",
    "new_col=cross_two('industryphy','enttypeitem')#作企业类型-小类的交叉特征\n",
    "data['industryphy_enttypeitem']=new_col\n",
    "#行业类别细类--企业类型小类的交叉特征\n",
    "new_col=cross_two('industryco','enttypeitem')#作企业类型-小类的交叉特征\n",
    "data['industryco_enttypeitem']=new_col\n",
    "new_col=cross_two('enttype','enttypegb_enttypeitem')#作企业类型-小类的交叉特征\n",
    "data['enttype_enttypegb_enttypeitem']=new_col\n",
    "#企业类型-小类-行业类别-细类的交叉特征\n",
    "new_col=cross_two('enttypegb_enttypeitem','industryphy_industryco')#作企业类型-小类的交叉特征\n",
    "data['enttypegb_enttypeitem_industryphy_industryco']=new_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fea in ['industryphy','enttype','enttypeitem','opfrom','regcap','opto','enttypeminu']:\n",
    "    data[fea+'_counts'] = data.groupby([fea])['id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data[data['label'].notnull()]\n",
    "y_train = x_train['label']\n",
    "x_test = data[data['label'].isnull()]\n",
    "features_name = [i for i in data.columns if i not in ['id','regcap','reccap','enttype','enttypeitem','enttypeminu','bucket_regcap_reccap','townsign','count_opscope','opscope_1','oplocdistrict','adbusign','compform','opform','orgid','exenum','opscope','enttypegb','label','state','jobid','regtype','parnum','venind','protype','oploc','forreccap','forregcap','congro']]\n",
    "#features_name = ['industryco', 'dom', 'opfrom', 'opto', 'empnum', 'enttpe_year', 'opscope_length', 'opscope_label', 'regcap_reccap', 'bucket_regcap', 'bucket_reccap', 'enttypegb_enttypeitem', 'industryphy_industryco', 'enttypegb_industryphy', 'industryphy_enttypeitem', 'industryco_enttypeitem', 'enttypegb_enttypeitem_industryphy_industryco', 'industryphy_counts', 'enttype_counts', 'enttypeitem_counts', 'empnum_counts', 'regcap_counts', 'opto_counts']\n",
    "x_train = x_train[features_name]\n",
    "x_test = x_test[features_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def combine(temp_list, n):\n",
    "    temp_list2 = []\n",
    "    for c in combinations(temp_list, n):\n",
    "        temp_list2.append(list(c))\n",
    "    return temp_list2\n",
    "\n",
    "list1 = x_train.columns.values\n",
    "end_list = []\n",
    "for i in range(24,len(list1)+1):\n",
    "    end_list.extend(combine(list1, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(end_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 模型\n",
    "rf = RandomForestClassifier(oob_score=True, random_state=2020,\n",
    "            n_estimators= 60,max_depth=13,min_samples_split=10)\n",
    "def stat_func(x):\n",
    "    l1 = []\n",
    "    for i in x:\n",
    "        if i>0.5:\n",
    "            a = 1\n",
    "            l1.append(a)\n",
    "        else:\n",
    "            a = 0\n",
    "            l1.append(a)\n",
    "    return l1\n",
    "def score_fuc(p,r):\n",
    "    return 2*p*r/(p+r)\n",
    "cat_list = [3]\n",
    "# 本地验证\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=2020)\n",
    "devscore = []\n",
    "tevscore = []\n",
    "count = 1\n",
    "result_test = pd.DataFrame()\n",
    "for tidx,didx in kf.split(x_train.index):\n",
    "    print('************************************ {} ************************************'.format(str(count)))\n",
    "    count += 1\n",
    "    tf = x_train.iloc[tidx]\n",
    "    df = x_train.iloc[didx]\n",
    "    tt = y_train.iloc[tidx]\n",
    "    dt = y_train.iloc[didx]\n",
    "    rf.fit(tf, tt)\n",
    "    pre_train = rf.predict(tf)\n",
    "    stat_pre_train = stat_func(pre_train)\n",
    "    p = precision_score(tt,stat_pre_train)\n",
    "    r = recall_score(tt,stat_pre_train)\n",
    "    score = score_fuc(p,r)\n",
    "    #score = f1_score(stat_pre_train,tt)\n",
    "    tevscore.append(score)\n",
    "    print(\"train F1：%s\"%score)\n",
    "    pre = rf.predict(df)\n",
    "    stat_pre = stat_func(pre)\n",
    "    p = precision_score(dt,stat_pre)\n",
    "    r = recall_score(dt,stat_pre)\n",
    "    score = score_fuc(p,r)\n",
    "    devscore.append(score)\n",
    "    print(\"Valid F1：%s\"%score)\n",
    "    result_test[str(count-1)+\"折\"] = rf.predict(x_test)/5\n",
    "print(\"Train average F1：%s\"%np.mean(tevscore),\"Valid average F1：%s\"%np.mean(devscore))\n",
    "result_test['result'] = result_test['1折']+result_test['2折']+result_test['3折']+result_test['4折']+result_test['5折']\n",
    "result = result_test['result'].values\n",
    "result_1 = stat_func(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name  = x_train.columns.tolist()\n",
    "feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "a = pd.DataFrame()\n",
    "feature_import = rf.feature_importances_\n",
    "feature_name  = x_train.columns.tolist()\n",
    "plt.barh(feature_name,feature_import)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entprise_test = pd.read_csv('../entprise_evaluate.csv')\n",
    "dict1 = {\n",
    "    'id':entprise_test.id,\n",
    "    'score':result_1\n",
    "}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entprise_test = pd.read_csv('../entprise_evaluate.csv')\n",
    "dict1 = {\n",
    "    'id':entprise_test.id,\n",
    "    'score':result_1\n",
    "}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.to_csv(r'../result/1121_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 模型\n",
    "def model_func(x_train_a,y_train_a):\n",
    "    rf = RandomForestClassifier(oob_score=True, random_state=2020,\n",
    "                n_estimators= 60,max_depth=13,min_samples_split=10)\n",
    "    def stat_func(x):\n",
    "        l1 = []\n",
    "        for i in x:\n",
    "            if i>0.5:\n",
    "                a = 1\n",
    "                l1.append(a)\n",
    "            else:\n",
    "                a = 0\n",
    "                l1.append(a)\n",
    "        return l1\n",
    "    def score_fuc(p,r):\n",
    "        return 2*p*r/(p+r)\n",
    "    cat_list = [3]\n",
    "    # 本地验证\n",
    "    kf = KFold(n_splits=5,shuffle=True,random_state=2020)\n",
    "    devscore = []\n",
    "    tevscore = []\n",
    "    count = 1\n",
    "#     result_test = pd.DataFrame()\n",
    "    for tidx,didx in kf.split(x_train_a.index):\n",
    "        #print('************************************ {} ************************************'.format(str(count)))\n",
    "        count += 1\n",
    "        tf = x_train_a.iloc[tidx]\n",
    "        df = x_train_a.iloc[didx]\n",
    "        tt = y_train_a.iloc[tidx]\n",
    "        dt = y_train_a.iloc[didx]\n",
    "        rf.fit(tf, tt)\n",
    "        pre_train = rf.predict(tf)\n",
    "        stat_pre_train = stat_func(pre_train)\n",
    "        p = precision_score(tt,stat_pre_train)\n",
    "        r = recall_score(tt,stat_pre_train)\n",
    "        score = score_fuc(p,r)\n",
    "        #score = f1_score(stat_pre_train,tt)\n",
    "        tevscore.append(score)\n",
    "        print(\"train F1：%s\"%score)\n",
    "        pre = rf.predict(df)\n",
    "        stat_pre = stat_func(pre)\n",
    "        p = precision_score(dt,stat_pre)\n",
    "        r = recall_score(dt,stat_pre)\n",
    "        score = score_fuc(p,r)\n",
    "        devscore.append(score)\n",
    "        print(\"Valid F1：%s\"%score)\n",
    "        result_test[str(count-1)+\"折\"] = rf.predict(x_test)/5\n",
    "    print(\"Train average F1：%s\"%np.mean(tevscore),\"Valid average F1：%s\"%np.mean(devscore))\n",
    "    return np.mean(devscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "best_dic = {}\n",
    "for n in end_list:\n",
    "    features_name = n\n",
    "    x_train_a = x_train[features_name]\n",
    "    x_test_a = x_test[features_name]\n",
    "    f1_score = model_func(x_train_a,y_train)\n",
    "    if f1_score>best:\n",
    "        best = f1_score\n",
    "        best_dic[best] = n\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['industryco', 'dom', 'opfrom', 'opto', 'empnum', 'enttpe_year', 'opscope_length', 'opscope_label', 'regcap_reccap', 'bucket_regcap', 'bucket_reccap', 'enttypegb_enttypeitem', 'industryphy_industryco', 'enttypegb_industryphy', 'industryphy_enttypeitem', 'industryco_enttypeitem', 'enttypegb_enttypeitem_industryphy_industryco', 'industryphy_counts', 'enttype_counts', 'enttypeitem_counts', 'empnum_counts', 'regcap_counts', 'opto_counts']\n",
    "len(l)\n",
    "#0.8514893338633541"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test['result'] = result_test['1折']+result_test['2折']+result_test['3折']+result_test['4折']+result_test['5折']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result_test['result'].values\n",
    "result_1 = stat_func(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "a = pd.DataFrame()\n",
    "feature_import = rf.feature_importances_\n",
    "feature_name  = x_train.columns.tolist()\n",
    "plt.barh(feature_name,feature_import)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entprise_test = pd.read_csv('entprise_evaluate.csv')\n",
    "dict1 = {\n",
    "    'id':entprise_test.id,\n",
    "    'score':result_1\n",
    "}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.to_csv(r'1115_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve,f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "#from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "# 模型\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=100,\n",
    "                              learning_rate=0.2, n_estimators=60, max_depth=5, \n",
    "                              metric='rmse', bagging_fraction = 1.0, feature_fraction = 1.0)\n",
    "def stat_func(x):\n",
    "    l1 = []\n",
    "    for i in x:\n",
    "        if i>0.5:\n",
    "            a = 1\n",
    "            l1.append(a)\n",
    "        else:\n",
    "            a = 0\n",
    "            l1.append(a)\n",
    "    return l1\n",
    "cat_list = [3]\n",
    "# 本地验证\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=2020)\n",
    "devscore = []\n",
    "tevscore = []\n",
    "count = 1\n",
    "result_test = pd.DataFrame()\n",
    "for tidx,didx in kf.split(x_train.index):\n",
    "    print('************************************ {} ************************************'.format(str(count)))\n",
    "    count += 1\n",
    "    tf = x_train.iloc[tidx]\n",
    "    df = x_train.iloc[didx]\n",
    "    tt = y_train.iloc[tidx]\n",
    "    dt = y_train.iloc[didx]\n",
    "    lgb_train = lgb.Dataset(tf,tt,free_raw_data=False)\n",
    "    lgb_eval = lgb.Dataset(df,dt,reference=lgb_train,free_raw_data=False)\n",
    "    model_lgb.fit(tf,tt)\n",
    "    #catr.fit(tf, tt,cat_features=cat_list)\n",
    "    pre_train = model_lgb.predict(tf)\n",
    "    stat_pre_train = stat_func(pre_train)\n",
    "    score = f1_score(stat_pre_train,tt)\n",
    "    tevscore.append(score)\n",
    "    print(\"train F1：%s\"%score)\n",
    "    pre = model_lgb.predict(df)\n",
    "    stat_pre = stat_func(pre)\n",
    "    score = f1_score(stat_pre,dt)\n",
    "    devscore.append(score)\n",
    "    print(\"Valid F1：%s\"%score)\n",
    "    result_test[str(count-1)+\"折\"] = rf.predict(x_test)/5\n",
    "print(\"Train average F1：%s\"%np.mean(tevscore),\"Valid average F1：%s\"%np.mean(devscore))\n",
    "result_test['result'] = result_test['1折']+result_test['2折']+result_test['3折']+result_test['4折']+result_test['5折']\n",
    "result = result_test['result'].values\n",
    "result_1 = stat_func(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entprise_test = pd.read_csv('../entprise_evaluate.csv')\n",
    "dict1 = {\n",
    "    'id':entprise_test.id,\n",
    "    'score':result_1\n",
    "}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entprise_test = pd.read_csv('../entprise_evaluate.csv')\n",
    "dict1 = {\n",
    "    'id':entprise_test.id,\n",
    "    'score':result_1\n",
    "}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.to_csv(r'../result/1120_2_lgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve,f1_score,precision_score,recall_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from catboost import CatBoostRegressor\n",
    "# 模型\n",
    "def makecatr():\n",
    "    params = {\n",
    "        \"learning_rate\":0.01,\n",
    "        'iterations':5000,\n",
    "        'depth': 5,\n",
    "        'l2_leaf_reg': 3,\n",
    "        'bootstrap_type':'Bernoulli',\n",
    "        'od_type': 'Iter',\n",
    "        'od_wait': 50,\n",
    "        'random_seed': 2020,\n",
    "        'allow_writing_files': False,\n",
    "        'task_type':'CPU',\n",
    "        'verbose':500,\n",
    "        'loss_function':'RMSE',\n",
    "    }\n",
    "    \n",
    "    catr = CatBoostRegressor(**params)\n",
    "    return catr\n",
    "def stat_func(x):\n",
    "    l1 = []\n",
    "    for i in x:\n",
    "        if i>0.5:\n",
    "            a = 1\n",
    "            l1.append(a)\n",
    "        else:\n",
    "            a = 0\n",
    "            l1.append(a)\n",
    "    return l1\n",
    "def score_fuc(p,r):\n",
    "    return 2*p*r/(p+r)\n",
    "cat_list = [3]\n",
    "# 本地验证\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=2020)\n",
    "devscore = []\n",
    "tevscore = []\n",
    "count = 1\n",
    "result_test = pd.DataFrame()\n",
    "for tidx,didx in kf.split(x_train.index):\n",
    "    print('************************************ {} ************************************'.format(str(count)))\n",
    "    count += 1\n",
    "    tf = x_train.iloc[tidx]\n",
    "    df = x_train.iloc[didx]\n",
    "    tt = y_train.iloc[tidx]\n",
    "    dt = y_train.iloc[didx]\n",
    "    catr = makecatr()\n",
    "    catr.fit(tf, tt,cat_features=cat_list)\n",
    "    pre_train = catr.predict(tf)\n",
    "    stat_pre_train = stat_func(pre_train)\n",
    "    p = precision_score(tt,stat_pre_train)\n",
    "    r = recall_score(tt,stat_pre_train)\n",
    "    score = score_fuc(p,r)\n",
    "    #score = f1_score(stat_pre_train,tt)\n",
    "    tevscore.append(score)\n",
    "    print(\"train F1：%s\"%score)\n",
    "    pre = catr.predict(df)\n",
    "    stat_pre = stat_func(pre)\n",
    "    p = precision_score(dt,stat_pre)\n",
    "    r = recall_score(dt,stat_pre)\n",
    "    score = score_fuc(p,r)\n",
    "    devscore.append(score)\n",
    "    result_test[str(count-1)+\"折\"] = rf.predict(x_test)/5\n",
    "    print(\"Valid F1：%s\"%score)\n",
    "print(\"Train average F1：%s\"%np.mean(tevscore),\"Valid average F1：%s\"%np.mean(devscore))\n",
    "result_test['result'] = result_test['1折']+result_test['2折']+result_test['3折']+result_test['4折']+result_test['5折']\n",
    "result = result_test['result'].values\n",
    "result_1 = stat_func(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entprise_test = pd.read_csv('entprise_evaluate.csv')\n",
    "dict1 = {\n",
    "    'id':entprise_test.id,\n",
    "    'score':result_1\n",
    "}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.to_csv(r'1115_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc, roc_curve,f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "#from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "# 模型\n",
    "params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'boosting': 'dart',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'learning_rate': 0.01,\n",
    "        'num_leaves':25,\n",
    "        'max_depth':3,\n",
    "        'max_bin':10,\n",
    "        'min_data_in_leaf':8,\n",
    "        'feature_fraction': 0.6,\n",
    "        'bagging_fraction': 1,\n",
    "        'bagging_freq':0,\n",
    "        'lambda_l1': 0,\n",
    "        'lambda_l2': 0,\n",
    "        'min_split_gain': 0\n",
    "}\n",
    "def stat_func(x):\n",
    "    l1 = []\n",
    "    for i in x:\n",
    "        if i>0.5:\n",
    "            a = 1\n",
    "            l1.append(a)\n",
    "        else:\n",
    "            a = 0\n",
    "            l1.append(a)\n",
    "    return l1\n",
    "cat_list = [3]\n",
    "# 本地验证\n",
    "kf = KFold(n_splits=5,shuffle=True,random_state=2020)\n",
    "devscore = []\n",
    "tevscore = []\n",
    "count = 1\n",
    "for tidx,didx in kf.split(x_train.index):\n",
    "    print('************************************ {} ************************************'.format(str(count)))\n",
    "    count += 1\n",
    "    tf = x_train.iloc[tidx]\n",
    "    df = x_train.iloc[didx]\n",
    "    tt = y_train.iloc[tidx]\n",
    "    dt = y_train.iloc[didx]\n",
    "    lgb_train = lgb.Dataset(tf,tt,free_raw_data=False)\n",
    "    lgb_eval = lgb.Dataset(df,dt,reference=lgb_train,free_raw_data=False)\n",
    "    gbm  = lgb.train(params,lgb_train,num_boost_round=2000,valid_sets=lgb_eval,verbose_eval=200)\n",
    "    #catr.fit(tf, tt,cat_features=cat_list)\n",
    "    pre_train = gbm.predict(tf)\n",
    "    stat_pre_train = stat_func(pre_train)\n",
    "    score = f1_score(stat_pre_train,tt)\n",
    "    tevscore.append(score)\n",
    "    print(\"train F1：%s\"%score)\n",
    "    pre = gbm.predict(df)\n",
    "    stat_pre = stat_func(pre)\n",
    "    score = f1_score(stat_pre,dt)\n",
    "    devscore.append(score)\n",
    "    print(\"Valid F1：%s\"%score)\n",
    "print(\"Train average F1：%s\"%np.mean(tevscore),\"Valid average F1：%s\"%np.mean(devscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entprise_test = pd.read_csv('entprise_evaluate.csv')\n",
    "dict1 = {\n",
    "    'id':entprise_test.id,\n",
    "    'score':pre\n",
    "}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.to_csv(r'1109_3.csv', index=False)\n",
    "# 0.82877408\n",
    "#0.8267"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(y_test,y_pre):\n",
    "    _,_,f_class,_=precision_recall_fscore_support(y_true=y_test,y_pred=y_pre,labels=[0,1],average=None)\n",
    "    fper_class={'合法':f_class[0],'违法':f_class[1],'f1':f1_score(y_test,y_pre)}\n",
    "    return fper_class\n",
    "#\n",
    "def k_fold_serachParmaters(model,train_val_data,train_val_kind):\n",
    "    mean_f1=0\n",
    "    mean_f1Train=0\n",
    "    n_splits=5\n",
    "    sk = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "    for train, test in sk.split(train_val_data, train_val_kind):\n",
    "        x_train = train_val_data.iloc[train]\n",
    "        y_train = train_val_kind.iloc[train]\n",
    "        x_test = train_val_data.iloc[test]\n",
    "        y_test = train_val_kind.iloc[test]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_test)\n",
    "        fper_class =  eval_score(y_test,pred)\n",
    "        mean_f1+=fper_class['f1']/n_splits\n",
    "        #print(fper_class)\n",
    "        \n",
    "        pred_Train = model.predict(x_train)\n",
    "        fper_class_train =  eval_score(y_train,pred_Train)\n",
    "        mean_f1Train+=fper_class_train['f1']/n_splits\n",
    "    #print('mean valf1:',mean_f1)\n",
    "    #print('mean trainf1:',mean_f1Train)\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(oob_score=True, random_state=2020,\n",
    "            n_estimators= 15,max_depth=19,min_samples_split=12)\n",
    "k_fold_serachParmaters(rf,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre1 = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entprise_test = pd.read_csv('entprise_evaluate.csv')\n",
    "dict1 = {\n",
    "    'id':entprise_test.id,\n",
    "    'score':pre1\n",
    "}\n",
    "df = pd.DataFrame(dict1)\n",
    "df.to_csv(r'1109_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = []\n",
    "for i in range(60,70):\n",
    "    n_estimators_list.append(int(i))\n",
    "min_samples_split_list = []\n",
    "for i in range(12,30):\n",
    "    min_samples_split_list.append(i)\n",
    "max_depth_list = []\n",
    "for i in range(19,30):\n",
    "    max_depth_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "\n",
    "def search_param(n_estimators,max_depth,min_samples_split):\n",
    "    rf = RandomForestClassifier(oob_score=True, random_state=2020,\n",
    "                    n_estimators= n_estimators,max_depth=max_depth,min_samples_split=min_samples_split)\n",
    "    mean_f1=k_fold_serachParmaters(rf,x_train,y_train)\n",
    "    return mean_f1\n",
    "\n",
    "#搜索最佳参数\n",
    "param=[]\n",
    "best=0\n",
    "for n_estimators in n_estimators_list:\n",
    "    print('n_estimators:',n_estimators)\n",
    "    for min_samples_split in min_samples_split_list:\n",
    "        for max_depth in max_depth_list:\n",
    "            mean_f1=search_param(n_estimators,max_depth,min_samples_split)\n",
    "            if mean_f1>best:\n",
    "                param=[n_estimators,min_samples_split,max_depth]\n",
    "                best=mean_f1\n",
    "                print(param,best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 15\n",
    "min_samples_split = 12\n",
    "max_depth = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.enttypeitem.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.regcap.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.reccap[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feas_importances_dict = {col:importance for col,importance in zip(list(x_train.columns),list(catr.feature_importances_))}\n",
    "print('Feature importances:\\n',feas_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feas_importances_dict = {col:importance for col,importance in zip(list(x_train.columns),list(catr.feature_importances_))}\n",
    "print('Feature importances:\\n',feas_importances_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'bucket_regcap_reccap'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
