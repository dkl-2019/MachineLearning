{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cab\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score,precision_recall_fscore_support,roc_curve,auc,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import gc\n",
    "#from featexp import get_univariate_plots#用于特征筛选，需要先安装featexp\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.rcParams['font.sans-serif']=['Simhei']\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info=pd.read_csv('train/base_info.csv')#企业的基本信息\n",
    "annual_report_info=pd.read_csv('train/annual_report_info.csv')#企业的年报基本信息\n",
    "tax_info=pd.read_csv('train/tax_info.csv')#企业的纳税信息\n",
    "change_info=pd.read_csv('train/tax_info.csv')#变更信息\n",
    "news_info=pd.read_csv('train/news_info.csv')#舆情信息\n",
    "other_info=pd.read_csv('train/other_info.csv')#其它信息\n",
    "entprise_info=pd.read_csv('train/entprise_info.csv')#企业标注信息{0: 13884, 1: 981}\n",
    "entprise_evaluate=pd.read_csv('entprise_evaluate.csv')#未标注信息\n",
    "\n",
    "print('base_info shape:',base_info.shape,'id unique:',len(base_info['id'].unique()))\n",
    "print('annual_report_info shape:',annual_report_info.shape,'id unique:',len(annual_report_info['id'].unique()))\n",
    "print('tax_info shape:',tax_info.shape,'id unique:',len(tax_info['id'].unique()))\n",
    "print('change_info shape:',change_info.shape,'id unique:',len(change_info['id'].unique()))\n",
    "print('news_info shape:',news_info.shape,'id unique:',len(news_info['id'].unique()))\n",
    "print('other_info shape:',other_info.shape,'id unique:',len(other_info['id'].unique()))\n",
    "print('entprise_info shape:',entprise_info.shape,'id unique:',len(entprise_info['id'].unique()))\n",
    "print('entprise_evaluate shape:',entprise_evaluate.shape,'id unique:',len(entprise_evaluate['id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面看一下具有企业年报信息和纳税信息的企业有多少是非法集资的企业\n",
    "#首先筛选出非法集资的企业\n",
    "illegal_id_list=[]\n",
    "legal_id_list=[]\n",
    "for index,name_id,flag in entprise_info.itertuples():\n",
    "    if flag==1:\n",
    "        illegal_id_list.append(name_id)\n",
    "    else:\n",
    "        legal_id_list.append(name_id)\n",
    "len(legal_id_list),len(illegal_id_list),len(legal_id_list)/len(illegal_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..................年报基本信息信息数据...................\n",
    "cnt_list_annual={'-1':0,'0':0,'1':0}\n",
    "for i in annual_report_info['id'].unique():\n",
    "    if i in illegal_id_list:\n",
    "        cnt_list_annual['1']+=1\n",
    "    elif i in legal_id_list:\n",
    "        cnt_list_annual['0']+=1\n",
    "    else:\n",
    "        cnt_list_annual['-1']+=1\n",
    "#具有年报基本信息的企业中，有536违法；2800合法；5601为测试集\n",
    "print(\"具有年报基本信息的企业中，有{}违法；{}合法；{}为测试集\".format(cnt_list_annual['1'],cnt_list_annual['0'],cnt_list_annual['-1']))\n",
    "#合法/违法:5.223880597014926，说明具有年报信息的企业，是非法的概率很高 由此可见，年报信息很重要，这是十分重要的特征\n",
    "print(\"具有年报基本信息的企业中：合法/违法:{}\".format(cnt_list_annual['0']/cnt_list_annual['1']))\n",
    "print(\"不具有年报基本信息的企业中：合法/违法:{}\".format((len(legal_id_list)-cnt_list_annual['0'])/(len(illegal_id_list)-cnt_list_annual['1'])))\n",
    "#由此可见，纳税信息很重要，这是十分重要的特征\n",
    "#...........................纳税信息news_info....................\n",
    "cnt_list_annual={'-1':0,'0':0,'1':0}\n",
    "for i in tax_info['id'].unique():\n",
    "    if i in illegal_id_list:\n",
    "        cnt_list_annual['1']+=1\n",
    "    elif i in legal_id_list:\n",
    "        cnt_list_annual['0']+=1\n",
    "    else:\n",
    "        cnt_list_annual['-1']+=1\n",
    "#具有年报基本信息的企业中，有536违法；2800合法；5601为测试集\n",
    "print(\"具有纳税基本信息的企业中，有{}违法；{}合法；{}为测试集\".format(cnt_list_annual['1'],cnt_list_annual['0'],cnt_list_annual['-1']))\n",
    "#合法/违法:5.223880597014926，说明具有年报信息的企业，是非法的概率很高 由此可见，年报信息很重要，这是十分重要的特征\n",
    "print(\"具有纳税信息的企业中：合法/违法:{}\".format(cnt_list_annual['0']/cnt_list_annual['1']))\n",
    "print(\"不具纳税信息的企业中：合法/违法:{}\".format((len(legal_id_list)-cnt_list_annual['0'])/(len(illegal_id_list)-cnt_list_annual['1'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理base_info的数据\n",
    "#空值大于0.5的列都删除掉\n",
    "annual_report_info_clean=annual_report_info.dropna(thresh=annual_report_info.shape[0]*0.5,how='all',axis=1)\n",
    "#对object类型进行编码\n",
    "annual_report_info_clean['BUSSTNAME']=annual_report_info_clean['BUSSTNAME'].fillna(\"无\")\n",
    "dic = {'无':-1,'开业':0, '歇业':1, '停业':2, '清算':3}\n",
    "buf = pd.DataFrame()\n",
    "buf_group = annual_report_info_clean.groupby('BUSSTNAME',sort=False)\n",
    "for name,group in buf_group:\n",
    "    group['BUSSTNAME'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "buf=buf.fillna(-1)\n",
    "#\n",
    "buf_group = buf.groupby('id',sort=False).agg('mean')\n",
    "buf=pd.DataFrame(buf_group).reset_index()\n",
    "annual_report_info_clean=buf.drop(['ANCHEYEAR'],axis=1)\n",
    "annual_report_info_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理tax数据\n",
    "tax_info_clean=tax_info.drop(['START_DATE','END_DATE'],axis=1)\n",
    "tax_info_clean['TAX_CATEGORIES']=tax_info_clean['TAX_CATEGORIES'].fillna(\"无\")\n",
    "tax_info_clean['TAX_ITEMS']=tax_info_clean['TAX_ITEMS'].fillna(\"无\")\n",
    "#对object类型进行编码\n",
    "# tax_info_clean['BUSSTNAME']=tax_infoclean['BUSSTNAME'].fillna(\"无\")\n",
    "dic={}\n",
    "cate=tax_info.TAX_CATEGORIES.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf = pd.DataFrame()\n",
    "buf_group = tax_info_clean.groupby('TAX_CATEGORIES',sort=False)\n",
    "for name,group in buf_group:\n",
    "    group['TAX_CATEGORIES'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "\n",
    "#\n",
    "dic={}\n",
    "cate=buf.TAX_ITEMS.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf_group = buf.groupby('TAX_ITEMS',sort=False)\n",
    "buf = pd.DataFrame()\n",
    "for name,group in buf_group:\n",
    "    group['TAX_ITEMS'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "buf=buf.fillna(-1)\n",
    "#\n",
    "buf_group = buf.groupby('id',sort=False).agg('mean')\n",
    "tax_info_clean=pd.DataFrame(buf_group).reset_index()\n",
    "tax_info_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #处理base_info数据\n",
    "base_info_clean=base_info.drop(['opscope','opfrom','opto'],axis=1)\n",
    "\n",
    "#............................对object类型进行编码...............................\n",
    "base_info_clean['industryphy']=base_info_clean['industryphy'].fillna(\"无\")\n",
    "base_info_clean['dom']=base_info_clean['dom'].fillna(\"无\")\n",
    "base_info_clean['opform']=base_info_clean['opform'].fillna(\"无\")\n",
    "base_info_clean['oploc']=base_info_clean['oploc'].fillna(\"无\")\n",
    "#\n",
    "dic={}\n",
    "cate=base_info_clean.industryphy.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf = pd.DataFrame()\n",
    "buf_group = base_info_clean.groupby('industryphy',sort=False)\n",
    "for name,group in buf_group:\n",
    "    group['industryphy'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "print('finished 1....')\n",
    "#\n",
    "dic={}\n",
    "cate=buf.dom.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf_group = buf.groupby('dom',sort=False)\n",
    "buf = pd.DataFrame()\n",
    "for name,group in buf_group:\n",
    "    group['dom'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "print('finished 2....')\n",
    "#\n",
    "dic={}\n",
    "cate=buf.opform.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf_group = buf.groupby('opform',sort=False)\n",
    "buf = pd.DataFrame()\n",
    "for name,group in buf_group:\n",
    "    group['opform'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "print('finished 3....')\n",
    "#\n",
    "dic={}\n",
    "cate=buf.oploc.unique()\n",
    "for i in range(len(cate)):\n",
    "    dic[cate[i]]=i\n",
    "\n",
    "buf_group = buf.groupby('oploc',sort=False)\n",
    "buf = pd.DataFrame()\n",
    "for name,group in buf_group:\n",
    "    group['oploc'] = dic[name]\n",
    "    buf = pd.concat([buf,group],ignore_index=True)\n",
    "print('finished 4....')\n",
    "#\n",
    "buf=buf.fillna(-1)\n",
    "#\n",
    "buf_group = buf.groupby('id',sort=False).agg('mean')\n",
    "base_info_clean=pd.DataFrame(buf_group).reset_index()\n",
    "#\n",
    "print('编码完毕.................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info_clean.to_csv('base_info_clean.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_info_clean = pd.read_csv('base_info_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucket(name,bucket_len):\n",
    "    gap_list=[base_info_clean[name].quantile(i/bucket_len) for i in range(bucket_len+1)]\n",
    "    len_data=len(base_info_clean[name])\n",
    "    new_col=[]\n",
    "    for i in base_info_clean[name].values:\n",
    "        for j in range(len(gap_list)):\n",
    "            if gap_list[j]>=i:\n",
    "                encode=j\n",
    "                break\n",
    "        new_col.append(encode)\n",
    "    return new_col\n",
    "#注册资本_实缴资本\n",
    "base_info_clean['regcap_reccap']=base_info_clean['regcap']-base_info_clean['reccap']\n",
    "#注册资本分桶\n",
    "base_info_clean['regcap']=base_info_clean['regcap'].fillna(base_info_clean['regcap'].median())\n",
    "base_info_clean['bucket_regcap']=bucket('regcap',5)\n",
    "#实缴资本分桶\n",
    "base_info_clean['reccap']=base_info_clean['reccap'].fillna(base_info_clean['reccap'].median())\n",
    "base_info_clean['bucket_reccap']=bucket('reccap',5)\n",
    "#注册资本_实缴资本分桶\n",
    "base_info_clean['regcap_reccap']=base_info_clean['regcap_reccap'].fillna(base_info_clean['regcap_reccap'].median())\n",
    "base_info_clean['bucket_regcap_reccap']=bucket('regcap_reccap',5)\n",
    "print('分桶完毕.................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def cross_two(name_1,name_2):\n",
    "    new_col=[]\n",
    "    encode=0\n",
    "    dic={}\n",
    "    val_1=base_info[name_1]\n",
    "    val_2=base_info[name_2]\n",
    "    for i in tqdm(range(len(val_1))):\n",
    "        tmp=str(val_1[i])+'_'+str(val_2[i])\n",
    "        if tmp in dic:\n",
    "            new_col.append(dic[tmp])\n",
    "        else:\n",
    "            dic[tmp]=encode\n",
    "            new_col.append(encode)\n",
    "            encode+=1\n",
    "    return new_col\n",
    "#作企业类型-小类的交叉特征\n",
    "base_info_clean['enttypegb']=base_info_clean['enttypegb'].fillna(\"无\")\n",
    "base_info_clean['enttypeitem']=base_info_clean['enttypeitem'].fillna(\"无\")\n",
    "new_col=cross_two('enttypegb','enttypeitem')#作企业类型-小类的交叉特征\n",
    "base_info_clean['enttypegb_enttypeitem']=new_col\n",
    "#\n",
    "#行业类别-细类的交叉特征\n",
    "base_info_clean['industryphy']=base_info_clean['industryphy'].fillna(\"无\")\n",
    "base_info_clean['industryco']=base_info_clean['industryco'].fillna(\"无\")\n",
    "new_col=cross_two('industryphy','industryco')#作企业类型-小类的交叉特征\n",
    "base_info_clean['industryphy_industryco']=new_col\n",
    "print('交叉特征完毕.................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features=['industryphy','dom','opform','oploc','bucket_regcap',\n",
    "              'bucket_reccap','bucket_regcap_reccap',\n",
    "              'enttypegb','enttypeitem','enttypegb_enttypeitem',\n",
    "              'industryphy','industryco','industryphy_industryco',\n",
    "              'adbusign','townsign','regtype','TAX_CATEGORIES'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#暂时可以利用企业基本信息，企业纳税信息，企业年度财报信息做义工merge然后进行我们的分类工作\n",
    "all_data=base_info_clean.merge(annual_report_info_clean,how='outer')\n",
    "all_data=all_data.merge(tax_info_clean,how='outer')\n",
    "all_data=all_data.fillna(-1)\n",
    "all_data.shape,base_info.shape,annual_report_info.shape,tax_info.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[cat_features]=all_data[cat_features].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train_data=all_data[all_data['id'].isin(entprise_info['id'].unique().tolist())]\n",
    "#train_data=train_data.reset_index(drop=True)\n",
    "train_df=all_data.merge(entprise_info)\n",
    "train_data=train_df.drop(['id','label'],axis=1)\n",
    "kind=train_df['label']\n",
    "test_df=all_data[all_data['id'].isin(entprise_evaluate['id'].unique().tolist())]\n",
    "test_df=test_df.reset_index(drop=True)\n",
    "test_data=test_df.drop(['id'],axis=1)\n",
    "train_data.shape,test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_score(y_test,y_pre):\n",
    "    _,_,f_class,_=precision_recall_fscore_support(y_true=y_test,y_pred=y_pre,labels=[0,1],average=None)\n",
    "    fper_class={'合法':f_class[0],'违法':f_class[1],'f1':f1_score(y_test,y_pre)}\n",
    "    return fper_class\n",
    "#\n",
    "def k_fold_serachParmaters(model,train_val_data,train_val_kind):\n",
    "    mean_f1=0\n",
    "    mean_f1Train=0\n",
    "    n_splits=5\n",
    "    sk = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2020)\n",
    "    for train, test in sk.split(train_val_data, train_val_kind):\n",
    "        x_train = train_val_data.iloc[train]\n",
    "        y_train = train_val_kind.iloc[train]\n",
    "        x_test = train_val_data.iloc[test]\n",
    "        y_test = train_val_kind.iloc[test]\n",
    "\n",
    "        model.fit(x_train, y_train)\n",
    "        pred = model.predict(x_test)\n",
    "        fper_class =  eval_score(y_test,pred)\n",
    "        mean_f1+=fper_class['f1']/n_splits\n",
    "        #print(fper_class)\n",
    "        \n",
    "        pred_Train = model.predict(x_train)\n",
    "        fper_class_train =  eval_score(y_train,pred_Train)\n",
    "        mean_f1Train+=fper_class_train['f1']/n_splits\n",
    "    #print('mean valf1:',mean_f1)\n",
    "    #print('mean trainf1:',mean_f1Train)\n",
    "    return mean_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_list = []\n",
    "for i in range(1,101):\n",
    "    n_estimators_list.append(int(i))\n",
    "min_samples_split_list = []\n",
    "for i in range(2,30):\n",
    "    min_samples_split_list.append(i)\n",
    "max_depth_list = []\n",
    "for i in range(2,30):\n",
    "    max_depth_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "\n",
    "def search_param(n_estimators,max_depth,min_samples_split):\n",
    "    rf = RandomForestClassifier(oob_score=True, random_state=2020,\n",
    "                    n_estimators= n_estimators,max_depth=max_depth,min_samples_split=min_samples_split)\n",
    "    mean_f1=k_fold_serachParmaters(rf,train_data,kind)\n",
    "    return mean_f1\n",
    "\n",
    "#搜索最佳参数\n",
    "param=[]\n",
    "best=0\n",
    "for n_estimators in n_estimators_list:\n",
    "    print('n_estimators:',n_estimators)\n",
    "    for min_samples_split in min_samples_split_list:\n",
    "        for max_depth in max_depth_list:\n",
    "            mean_f1=search_param(n_estimators,max_depth,min_samples_split)\n",
    "            if mean_f1>best:\n",
    "                param=[n_estimators,min_samples_split,max_depth]\n",
    "                best=mean_f1\n",
    "                print(param,best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
